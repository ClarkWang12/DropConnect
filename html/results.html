<html>
<head>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Final Project cs152 -- Implementation</title>
<script type="text/x-mathjax-config">

MathJax.Hub.Config({

  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}

});
</script>
<script type="text/javascript"
  src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<link href="http://getbootstrap.com/dist/css/bootstrap.css" rel="stylesheet">
<link href="http://getbootstrap.com/examples/blog/blog.css" rel="stylesheet">
<link href='~/public_html/p.css' rel="stylesheet">
</head>
<body>
    <div class="blog-masthead">
      <div class="container">
        <nav class="blog-nav">
          <a class="blog-nav-item" href="main.html">Main</a>
          <a class="blog-nav-item" href="motivation.html">Motivation</a>
          <a class="blog-nav-item" href="implementation.html">Implementation</a>
          <a class="blog-nav-item" href="testing.html">Testing</a>
          <a class="blog-nav-item active" href="results.html">Results</a>
        </nav>
      </div>
    </div>
    <div class="container">
      <div class="blog-header">
      </div>
      <div class="row">
        <div class="col-sm-11 blog-main">
          <div class="blog-post">

 <h2 class="blog-post-title">DropConnect Network Results</h2>
 <h3>Classification</h3>
<p> To test the performance of our networks once we trained them we initially turned to the datasets supplied to us in the beginning
of the semester both because they present challenging non-linear decision boundaries and also because of our familiarity with them.
One of the more difficult classification sets was the cancer data because patients with similar symptoms can have vastly different
diagnoses. 
<p> The performance of the no-drop networks exhibits classic signs of overfitting, where the training error continues to decrease
at the expense of generalization; the validation error ticks up as the network overfits.
<center>
<img src="http://www.cs.hmc.edu/~jderose/images/overfit.jpg" alt="No-drop network performance: cancer data" height="200" width="450"/>
</center>
<p> However just switching to the DropConnect algorithm gives the following results:
<center>
<img src="http://www.cs.hmc.edu/~jderose/images/CancerDropConnect.jpg" alt="DropConnect network performance: cancer data" height="200" width="450"/>
</center>
Although the validation set seems to jump around a lot initially, the results are very positive. Not only does the 
validation set not experience a degredation in perfomance as time goes on, it actually out performs
the training set. The network is making good generalizations during training that translate well to the
testing performance.
<p> We observed similar performance on the iris setosa dataset. The no-drop network performs very well on this 
data. So well, in fact, that it's hard to even see the lines being plotting because we achieve zero errors
on both sets very quickly:
<center>
<img src="http://www.cs.hmc.edu/~jderose/images/NoDropSetosa.jpg" alt="No-drop network performance: iris setosa data" height="200" width="450"/>
</center>
The DropConnect network is, eventually, able to match the performance of the no drop network on the iris setosa data:
<center>
<img src="http://www.cs.hmc.edu/~jderose/images/SetosaDropConnect.jpg" alt="No-drop network performance: iris setosa data" height="200" width="450"/>
</center>
It takes longer, exactly as we would expect, for the DropConnect network to reach the level of performance
of the no drop network but nonetheless it does. An interesting point is that the training performance of the 
DropConnect network never reaches the level of the no drop network. Even then, DropConnect's ability to
correctly classify data it has never seen before is on-par or better than the no drop network.
<p>
<h3>Regression</h3>
To round out our performance evaluation of the DropConnect algorithm's performance, we chose to use the carbig.mat 
data, which contains 683 measurements of cars from 1970-1982. In our tests, we regressed the weight of the car
on acceleration, number of cylinders, engine displacement, and horsepower. Below, we see the results
of using a no drop network:
<center>
<img src="http://www.cs.hmc.edu/~jderose/images/NoDropCars.jpg" alt="No-drop network performance: carbig.mat data" height="200" width="450"/>
</center>
Again, we see indications of overfitting as the validation error initially drops in step with the training error
only to begin creeping back up for the rest of the training period. In certain cases, users of 
neural networks may stop early to prevent just this sort of overfitting. DropConnect's aim is to avoid 
it entirely and the perscription is to stop stopping early and start using DropOut or DropConnect. However,
in this case the DropConnect network fails to match the performance of the no drop net:
<center>
<img src="http://www.cs.hmc.edu/~jderose/images/DropConnectCars.jpg" alt="DropConnect network performance: iris setosa data" height="200" width="450"/>
</center>
This result is not a deal-breaker, though. 
<p>In fact, even though in a few other cases, like when using around 400 hidden units,
we noticed the training and validation error to decrease quickly at the start but then get stuck and remain constant
for the entirety of the training:
<center>
<img src="http://www.cs.hmc.edu/~jderose/images/flatline.jpg" height="200" width="450"/>
</center>
 We believe this is not a failure of the DropConnect algorithm but rather of our own poorly initialized weights. Both the "initialization and momentum are crucial" (<a href="http://www.cs.toronto.edu/~fritz/absps/momentum.pdf">Sutskever et al.</a>) to performance. More hidden units lead to more complex error surfaces that require better parameter selection to prevent convergence to local minima. Our use of stochastic gradient descent, as opposed to using conjugate-gradient descent or choosing a more intelligently momentum schedule, was relatively easy to implement but may also be holding us back from the true potential of the DropConnect network.
<p> Further, it is entirely possible to train multiple DropConnect networks and use them all as an ensemble. This
amounts to a sort of meta-ensemble because each of the individual networks functions as a mixture model. In practice,
each one will probably see a different subset of the data, or will at least be training using different masking matrices,
so that the information among them is distributed. One could conceivably construct a way to use the individual networks
to reach a consensus on their output for improved performance. It is also interesting to consider the use of a softmax function in the output layer of the network to do multi-class classification. Such a function maps outputs from the non-linearity applied to the output layer to a probability distribution. One could concievably imagine using a genetic algorithm to optimally weight the votes of each network. Geoffrey Hinton discusses why the softmax function, and its associated cost function, are good choices for multi-class classification.
<center>
<iframe width="400" height="315" src="//www.youtube.com/embed/UI-QnjgMgNY" frameborder="0" allowfullscreen></iframe>
</center>
</body>
</html>
<p>
<p>It should also be noted that the main authors used 20% DropOut/DropConnect on the input layer to their network. We
tried a similar approach, but believe the data we are dealing with to be too sparse. With 10,000 training examples, it
makes sense to omit 20% of each input vector. With only 300, the game changes entirely. We did not observe a significant improvement
in either classification or regression when we dropped information from the input layer. 
<p>  
          </div><!-- /.blog-post -->
          <ul class="pager">
	    <li><a href="testing.html">Previous</a></li>
            <li><a href="results.html">Next</a></li>
          </ul>
        </div><!-- /.blog-main -->
      </div><!-- /.row -->
    </div><!-- /.container -->
    <div class="blog-footer">
      <p>Blog template built for <a href="http://getbootstrap.com">Bootstrap</a></p>
      <p>
        <a href="#">Back to top</a>
      </p>
    </div>
  </body>
</body>
</html>
