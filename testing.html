<html>
<head>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Final Project cs152 -- Implementation</title>
<script type="text/x-mathjax-config">

MathJax.Hub.Config({

  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}

});
</script>
<script type="text/javascript"
  src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<link href="http://getbootstrap.com/dist/css/bootstrap.css" rel="stylesheet">
<link href="http://getbootstrap.com/examples/blog/blog.css" rel="stylesheet">
</head>
<body>
    <div class="blog-masthead">
      <div class="container">
        <nav class="blog-nav">
          <a class="blog-nav-item" href="main.html">Main</a>
          <a class="blog-nav-item" href="motivation.html">Motivation</a>
          <a class="blog-nav-item" href="implementation.html">Implementation</a>
          <a class="blog-nav-item active" href="testing.html">Testing</a>
          <a class="blog-nav-item" href="results.html">Results</a>
        </nav>
      </div>
    </div>
    <div class="container">
      <div class="blog-header">
      </div>
      <div class="row">
        <div class="col-sm-11 blog-main">
          <div class="blog-post">

 <h2 class="blog-post-title">Inferring with a DropConnect Network</h2>
<p>In a no-drop neural network, once we have trained the network we simply apply the input vector we want to classify/regress on to the input nodes of the newtork and propigate the signal through to the output layer. With a DropConnect network, the testing phase is a little different because each training sample uses a (possibly) unique version of the network due to the fact that some of the weight connections are dropped.
<p>We take a momentary detour to discuss the expectation of discrete random variables. The result will shed light on the ensuing discussion of the inference process. Let $X$ be a discrete random variable and $g$ be some function on that variable. In computing computing the expectation of $g(x)$, we have:
$$E[g(X)] = \sum_x g(x)\cdot f_X(x)$$
Where $f_X$ is the $pmf$ of the random variable; i.e. $f_X(x)$ gives $\text{Pr}(X = x)$. This result follows from elementary probability.
<p>In our case, we let $f(x; \theta, M)$ denote the output of the DropConect model given an input vector $x$, model parameters $\theta$, and masking matrix $M$. We want to compute the expected value of $f$, which requires taking into consideration all possible masking matrices. Note that $f$ is a function of a discrete random variable, $M$ so we may apply what we know about its expectation:
$$E[f(x;\theta, M)] = \sum_M f(x; \theta, M) \cdot f_M(M)$$
Thus revealing the mixture model interpretation of DropConnect. The output, or expected value, is a mixture of all possible networks.
<p> Things begin to get complicated here because if $M$ is the set of all possible masks, then there are $2^{|M|}$ possible networks (Do you see why? For each network, we can either use a mask or not). Thus, computing the expectation becomes infeasible due to the cardinality of the masking matrices is too great.
<p>We are in luck, though, because we saw in the previous section that each neuron's activation is a linear combination of Bernoulli random variables. The Central Limit Theorem lets us approximate a Binomial$(n,p)$ distribution with a $\mathcal{N}(np, np(1-p))$, so that instead of averaging over all possible networks, we compute the layer response as test time by <a href="http://cs.nyu.edu/~wanli/dropc/dropc_slides.pdf">sampling</a> or numeric integration. Further, we can sample each response independently so that the task is easily parallelizable and much more effecient.
<center>
<img src="norm.jpg" >
          </div><!-- /.blog-post -->
          <ul class="pager">
	    <li><a href="testing.html">Previous</a></li>
            <li><a href="results.html">Next</a></li>
          </ul>
        </div><!-- /.blog-main -->
      </div><!-- /.row -->
    </div><!-- /.container -->
    <div class="blog-footer">
      <p>Blog template built for <a href="http://getbootstrap.com">Bootstrap</a></p>
      <p>
        <a href="#">Back to top</a>
      </p>
    </div>
  </body>
</body>
</html>
